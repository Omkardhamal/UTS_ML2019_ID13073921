{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omkardhamal/UTS_ML2019_ID13073921/blob/master/A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjmSN6Y15737",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnVcTUwwe7cm",
        "colab_type": "text"
      },
      "source": [
        "#Review Report on \"Generative Adversarial Nets\"\n",
        "\n",
        "##Introduction\n",
        "\n",
        "Over the most recent couple of years, a kind of generative model known as Generative Adversarial Networks (GANs), has made huge progress in the field of IT vision, Image recognition, speech and language training, and so on. GANs are the models which are utilized to deliver new examples which have comparable information circulation as of the preparation dataset. In this paper, I will initially present the thought behind the GANs, trailed by the application extend and lastly the future work with its related research.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Content\n",
        "\n",
        "Ian Goodfellow has proposed a deep generative system called “Generative Adversarial Nets”, which comprises of a generative model G and discriminative model D, both together, are trained at the same time. Ian Goodfellow came up with an excellent similarity which depict their relationship. Generative model resembles a group of forgers attempting to deliver fake cash without being distinguished. Discriminative model resembles to the police, who consistently distinguish and stop the dissemination of fake cash.\n",
        "Suppose at Day 0 the forgers produce their first lot of fake cash and attempt to shop, anyway the nature of phony cash is terrible to such an extent that police can promptly spot it out within a fraction of a second.  At day 1, forgers produce another lot of fake cash, perhaps utilizing better ink or bigger paper note? At that point forgers attempt their karma and check whether the police will spot them. Gracious well! the police can detect the fake cash once more, however this time, he invests extra time/miss one note affirming this cash is phony.  This implies the nature of phony cash has expanded contrast from our day 0. Forgers gain from the past misstep and improve the structure of phony cash. Repeat this circle at day 30, the forgers possibly ready to create top-notch counterfeit cash that the police feel hard to recognize. This in actuality includes misfortune capacity, backpropagation and training. \n",
        "This same logic applies to the GANs, the generative model will catch information dissemination and attempting to augment the likelihood of D to commit error. While the discriminative model D gauge the likelihood that an example originated from preparing information as opposed to G. The entire system resembles a minimax two player game. D is trained to augment the likelihood of relegating the right mark to both training models and tests from G. And at the same time G is trained to limit \n",
        "\n",
        "log(1 - D(G(z))):\n",
        "\n",
        "As such, D and G play the accompanying two-player minimax game with Value Function V (G;D):\n",
        " \n",
        "##Innovation\n",
        "\n",
        "The guarantee of deep learning is to find rich, various leveled models that speak to likelihood circulations over the sorts of information experienced in AI applications, for example, natural pictures, sound waveforms containing discourse, and images in characteristic language corpora. Up until now, the most striking accomplishments in deep learning have included discriminative models, ordinarily those that guide a high-dimensional, rich tangible contribution to a class name. These striking victories have essentially been founded on the backpropagation and failed algorithms, utilizing piecewise linear units which have an especially polite gradient. Deep generative models have had less of an effect, because of the trouble of approximating numerous unmanageable probabilistic calculations that emerge in most extreme probability estimation and related procedures, and because of the trouble of utilizing the advantages of piecewise linear units in the generative setting. Ian Goodfellow proposed another generative model estimation methodology that avoids these challenges.\n",
        "Compared to other classification models GAN is superior to all of them because of the following reasons:\n",
        "•\tGANs produce tests quicker than completely noticeable conviction nets (NADE, PixelRNN, WaveNet) because there is no compelling reason to create the various sections in the example consecutively. \n",
        "\n",
        "•\tGANs needn't bother with any Monte Carlo approximations to prepare. Individuals whine about GANs being flimsy and hard to prepare, however they are a lot simpler to prepare than Boltzmann machines, which depended on Monte Carlo approximations to the gradient of the log segment work. Since Monte Carlo techniques don't work well in high dimensional spaces, Boltzmann machines have not truly scaled to practical errands like ImageNet. GANs at any rate ready to figure out how to draw a couple wrecked dog images when trained on ImageNet. \n",
        "\n",
        "•\tContrasted with variational autoencoders, GANs don't present any deterministic inclination. Variational techniques present deterministic inclination since they upgrade a lower bound on the log-probability instead of the probability itself. This appears to result in VAEs figuring out how to produce foggy examples contrasted with GANs. \n",
        "\n",
        "•\tContrasted with nonlinear ICA (NICE, Real NVE, and so forth being the latest models), there is no necessity that the dormant code have a particular dimensionality or that the generator net be invertible. \n",
        "\n",
        "•\tContrasted with VAEs, it's simpler to utilize discrete inert factors. \n",
        "\n",
        "•\tContrasted with Boltzmann machines and GSNs, producing an example requires just one go through the model, as opposed to an obscure number of cycles of a Markov chain.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Technical Quality\n",
        "\n",
        "The basic framework of GAN consists of two different neural networks namely the generator and the discriminator. Each model attempts to decide how well it can get the most result. The generator model consists of a differential function, it is represented symbolically as follows:\n",
        "x=G(z;θ(G))\n",
        "Where, z is the vector that contains the inactive code and x is the watched variable produced by the generator. The discriminator D isn't generally needed once the generator is effectively ready to create practical information. The essential job of the discriminator is to assess an example to see whether the example looks genuine or counterfeit. The discriminator function is similar to the generator function.\n",
        "\n",
        "<img src=\"https://github.com/Omkardhamal/UTS_ML2019_ID13073921/blob/master/1.png?raw=true\">\n",
        "FIGURE 1: GAN PROTOTYPE\n",
        "\n",
        "The Algorithm 1 below comprises of testing a minibatch from both the training set and the created set and running the discriminator on those data sources. the training of the generator is started by examining the idle vector z from the earlier conveyance over the idle factors, z is basically a vector of unstructured clamor. It enables the generator to yield a wide range of vectors.\n",
        "\n",
        "<img src=\"https://github.com/Omkardhamal/UTS_ML2019_ID13073921/blob/master/2.png?raw=true\">\n",
        "GAN TRAINING ALGORITHM\n",
        "\n",
        "The generator function is then applied to the vector z. The generator yields an example that is then connected to the discriminator. The discriminator yields a worth which is basically a twofold arrangement of genuine or phony. The blunder misfortune on the discriminator's output is determined to utilize a cross-entropy cost work. This error is then backpropagated to both the generator and the discriminator systems. Training halts when the discriminator can never again separate between a produced information and training information. This point is known as the saddle point of the discriminator misfortune, and on a basic level ought to be the global least.\n",
        "\n",
        "\n",
        "##Application and X-Factor\n",
        "\n",
        "As far as per my knowledge, the principal advantage of utilizing generative adversarial networks (GANs) is, when it functions, it functions truly well, as has been proved by Ian Goodfellow that it generates reasonable pictures of faces, objects and creatures. The purpose behind this is the target improved by GANs - to create fake information that is unclear from genuine information by another neural net - is exceptionally lined up with the objective of delivering sensible information. This is rather than a contending strategy \"variational autoencoders\", which has a seemingly less-adjusted goal. Notwithstanding having a superior target, GANs don't require a great deal of the earlier and back likelihood computations regularly important for another contending approach, most extreme probability.\n",
        "But this algorithm also has a few cons too. One of the biggest cons is that these systems are difficult to train. The capacity these systems attempt to streamline is a misfortune work that basically has no shut structure (dissimilar to standard misfortune capacities like log-misfortune or squared blunder). Subsequently, improving this misfortune capacity is exceptionally hard and requires a great deal of experimentation with respect to the system structure and preparing convention.\n",
        "###Applications of GAN\n",
        "\n",
        "•\tPicture Creation: Generative systems can be utilized to create practical pictures subsequent to being trained on test pictures. For instance, on the off chance that we need to create new pictures of canines, we can prepare a GAN on many set of pictures of canines. Once the training has been completed, the generator system will most likely create new pictures that are not the same as the pictures in the training set. (Subscription.packtpub.com, 2019) \n",
        "•\tFace Ageing: This can be valuable for both the amusement and reconnaissance enterprises. It is especially valuable for face check since it implies that an organization doesn't have to change their security frameworks as individuals age.\n",
        "•\tVideo Creation: GANs can likewise be utilized to create recordings. They can produce content in less amount of time than if we somehow happened to make content manually. Recently, Samsung generated a video by using just a single image of an individual and then combining it with text, the output was a video in which the individual could be seen lip-sync th the provided text.\n",
        "•\tGAN can be used to complete an image which has missing parts in it.\n",
        "\n",
        "<img src=\"https://github.com/Omkardhamal/UTS_ML2019_ID13073921/blob/master/3.png?raw=true\"> \n",
        "FIGURE 2: POSE GUIDED PERSON IMAGE GENERATION (GOODFELLOW 2014)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Presentation\n",
        "\n",
        "The format of the given reference paper is unclear. It is very complex to understand what the author wants to prove. I needed help from external papers and websites to the basic understanding of GANs.\n",
        "Other than that, I found that the following can be the future related works for GANs. The mixes of GANs with various building models can likewise be utilized for content to-picture union. Besides, GANs are still generally utilized distinctly in IT vision related issues however they can likewise be reached out to the field of sound and video areas. GANs have additionally begun to demonstrate its essence in medication disclosure for human services utilizing ChemGAN (Benhenda M. 2017). \n",
        "The expanding spaces of utilizations prompts testing issues which are very mind boggling, therefore requesting dynamic research work and advancements in generative models.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##References\n",
        "\n",
        "I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in Advances in Neural Information Processing Systems 27, Montreal, Quebec, Canada, 2014, pp.2672−2680.\n",
        "Mostapha Benhenda ,” ChemGAN challenge for drug discovery: can AI reproduce natural chemical diversity?”, arXiv:1708.08227v3 [stat.ML] , Aug 2017\n"
      ]
    }
  ]
}